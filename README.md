# ğŸ“š Local LLM Document Agent

This project is a local Retrieval-Augmented Generation (RAG) system that allows users to query personal PDF/EPUB documents using a local Large Language Model (LLM). It integrates document parsing, vector embedding, FAISS indexing, and a CLI/Streamlit Web UI powered by Ollama + llama3.

---

## âš™ï¸ Prerequisites

- Python 3.9+ (recommended via [Miniconda](https://docs.conda.io/en/latest/miniconda.html))
- Ollama (to run local LLMs like `llama3`): [https://ollama.com](https://ollama.com)
- Git
- Virtual environment tool (conda or venv)
- macOS/Linux (tested), Windows WSL2 might work

---

## ğŸ“ Project Structure

```
LLM_Document_Agent/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ui.py              # CLI interface
â”‚   â””â”€â”€ web_ui.py          # Streamlit Web UI
â”œâ”€â”€ ingest/
â”‚   â”œâ”€â”€ parser.py          # Parses and caches documents
â”‚   â””â”€â”€ chunk_embed.py     # Text splitting + embedding + FAISS index
â”œâ”€â”€ query/
â”‚   â””â”€â”€ rag_chain.py       # Vector search + LLM chat interface
â”œâ”€â”€ llm_parsers/
â”‚   â””â”€â”€ parsers.py         # .pdf/.epub parsing logic
â”œâ”€â”€ store/                 # Stores index + metadata
â”œâ”€â”€ docs/                  # Your documents (PDF, EPUB)
â”œâ”€â”€ run_pipeline.sh        # Pipeline automation script
â””â”€â”€ README.md
```

---

## ğŸ“¦ Installation

1. **Clone the repository**

```bash
git clone <your_repo_url>
cd LLM_Document_Agent
```

2. **Set up environment (conda)**

```bash
conda create -n llm-rag python=3.9 -y
conda activate llm-rag
```

3. **Install Python packages**

```bash
pip install -r requirements.txt
# If not available, install manually:
pip install streamlit faiss-cpu langchain sentence-transformers ebooklib beautifulsoup4 unstructured ollama
```

4. **Start Ollama server in background**

```bash
ollama serve &
ollama run llama3  # will download model if needed
```

---

## ğŸš€ Usage

### Full pipeline (parse + embed + UI)

```bash
./run_pipeline.sh --gui  # Streamlit UI
./run_pipeline.sh --cli  # Terminal-based CLI
```

### Upload documents
Place your `.pdf` or `.epub` files in the `docs/` directory.

### Ask questions
- Web UI: Type natural questions like "Summarize this book" or "What did Miyazaki do in 1979?"
- CLI: Same functionality via terminal

---

## ğŸ§  Features

- PDF & EPUB parsing with character-normalized filenames (NFKC-safe)
- Automatic caching to avoid redundant re-parsing and re-embedding
- SentenceTransformer embedding (`intfloat/multilingual-e5-base`)
- FAISS vector index + metadata persistence
- LLM queries via Ollama (`llama3`, switchable)
- Streamlit Web UI or CLI interface

---

## âœ¨ Planned Improvements

### Functional Enhancements
- âœ… Incremental FAISS index updates (avoid full reprocessing)
- âœ… Handle multilingual filenames safely (Unicode normalization)
- âœ… Display source chunks and citation in answers
- ğŸ”² Upload documents via Streamlit UI
- ğŸ”² Select which documents to include in search
- ğŸ”² Better session & scroll handling in Web UI
- ğŸ”² Prompt templates & chain-of-thought enhancement
- ğŸ”² Option to switch between Ollama local LLM and OpenAI models

### Codebase Architecture
- ğŸ”² Clean up `PYTHONPATH` issues via modular packaging (`src/` style layout)
- ğŸ”² Rename `utils` to avoid naming conflicts (`llm_parsers`, etc.)
- ğŸ”² Move all logs and caches to dedicated folders (`.cache/`, `logs/`)
- ğŸ”² Add basic `pytest` tests for parsing and querying flow
- ğŸ”² Dockerize the app for easier deployment

### Documentation & CI/CD
- ğŸ”² Add license file (MIT/Apache2.0)
- ğŸ”² Include usage examples, screenshots & animated GIF
- ğŸ”² GitHub Actions for test/lint checks on push
- ğŸ”² Add public demo via Streamlit Cloud (optional)

### Future Features
- ğŸ”² LangChain/LLamaIndex adapter layer for advanced agent behavior
- ğŸ”² Chunk overlap tuning and top-k selection in UI/config
- ğŸ”² Document-type icons or filters in UI

---

## ğŸ§‘â€ğŸ’» Author
Developed collaboratively with GPT-4o and driven by precision, performance, and the vision of AI-human creative collaboration.

> "I hate lies." â€” Project Owner
