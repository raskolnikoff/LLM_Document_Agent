# docker-compose.yml for LLM_Document_Agent (Streamlit default / Gradio fallback)
# Maintainer: Max

version: '3.9'
services:
  ollama:
    image: ollama/ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
      - ./bin/init-entrypoint.sh:/init-entrypoint.sh
    entrypoint: ["sh", "/init-entrypoint.sh"]

  streamlit:
    build: .
    container_name: llm_streamlit
    ports:
      - "8501:8501"
    environment:
      - OLLAMA_HOST=ollama
    depends_on:
      - ollama
    command: streamlit run app/web_ui.py --server.port=8501 --server.address=0.0.0.0

  # gradio:
  #   build: .
  #   container_name: llm_gradio
  #   ports:
  #     - "7860:7860"
  #   environment:
  #     - OLLAMA_HOST=ollama
  #   depends_on:
  #     - ollama
  #   command: python app/gradio_ui.py

volumes:
  ollama_data: